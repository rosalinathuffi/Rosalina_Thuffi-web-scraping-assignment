#install selenium
!pip install selenium
!apt-get update
!apt install -y chromium-chromedriver

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time
import pandas as pd

# Set up Chrome options
chrome_options = Options()
chrome_options.add_argument("--headless")  # Ensure GUI is off
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")

# Set the path to the ChromeDriver executable
driver = webdriver.Chrome(options=chrome_options)

# URL of the eBay page
url = 'https://www.ebay.com/b/Jordan-4-Retro-Mid-White-Oreo/15709/bn_7117719164'
driver.get(url)
time.sleep(5)  # Allow time for the page to fully load

# Parse the page source with BeautifulSoup
soup = BeautifulSoup(driver.page_source, 'html.parser')

driver.quit()

# Create empty lists to store data
titles = []
image_urls = []
prices = []

# Find the product containers
products = soup.find_all('div', class_='brwrvr__item-card__body')

if products:
    for product in products:
        # Get the title
        title_tag = product.find('h3', class_='textual-display bsig__title__text')
        title = title_tag.text.strip() if title_tag else 'No Title'
        titles.append(title)

        # Get the image URL
        image_tag = product.find('img')
        image_url = image_tag['src'] if image_tag else 'No Image'
        image_urls.append(image_url)

        # Get the price
        price_tag = product.find('span', class_='textual-display bsig__price bsig__price--displayprice')
        price = price_tag.text.strip() if price_tag else 'No Price'
        prices.append(price)

    # Create a pandas DataFrame
    data = pd.DataFrame({
        'Title': titles,
        'Image URL': image_urls,
        'Price': prices
    })

    # Save to a CSV file
    data.to_csv('scraped_ebay_products2.csv', index=False)

    print("Data saved to scraped_ebay_products2.csv")
else:
    print("No products found")
